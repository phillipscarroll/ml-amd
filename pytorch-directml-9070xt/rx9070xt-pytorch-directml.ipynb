{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RX 9070 XT DirectML Testing\n",
    "\n",
    "Moving from my README.md notes to this notebook for faster iteration. I can get PyTorch to work on DirectML but it feels hacky and I need to work out the details of what exact packages I need etc... I would like to get the requirements locked down so I can test (even if very slow compared to native/ROCm) on this new GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pip list - Current semi-working state\n",
    "\n",
    "```\n",
    "Package                   Version\n",
    "------------------------- ---------------\n",
    "aiofiles                  23.2.1\n",
    "altair                    5.5.0\n",
    "annotated-types           0.7.0\n",
    "anyio                     4.9.0\n",
    "argon2-cffi               23.1.0\n",
    "argon2-cffi-bindings      21.2.0\n",
    "arrow                     1.3.0\n",
    "asttokens                 3.0.0\n",
    "async-lru                 2.0.5\n",
    "attrs                     25.3.0\n",
    "babel                     2.17.0\n",
    "beautifulsoup4            4.13.3\n",
    "bleach                    6.2.0\n",
    "certifi                   2025.1.31\n",
    "cffi                      1.17.1\n",
    "charset-normalizer        3.4.1\n",
    "click                     8.1.8\n",
    "colorama                  0.4.6\n",
    "comm                      0.2.2\n",
    "contourpy                 1.3.1\n",
    "cycler                    0.12.1\n",
    "debugpy                   1.8.13\n",
    "decorator                 5.2.1\n",
    "defusedxml                0.7.1\n",
    "diffusers                 0.32.2\n",
    "executing                 2.2.0\n",
    "fastapi                   0.115.11\n",
    "fastjsonschema            2.21.1\n",
    "ffmpy                     0.5.0\n",
    "filelock                  3.18.0\n",
    "fonttools                 4.56.0\n",
    "fqdn                      1.5.1\n",
    "fsspec                    2025.3.0\n",
    "gradio                    3.48.0\n",
    "gradio_client             0.6.1\n",
    "groovy                    0.1.2\n",
    "h11                       0.14.0\n",
    "httpcore                  1.0.7\n",
    "httpx                     0.28.1\n",
    "huggingface-hub           0.29.3\n",
    "idna                      3.10\n",
    "importlib_metadata        8.6.1\n",
    "importlib_resources       6.5.2\n",
    "ipykernel                 6.29.5\n",
    "ipython                   9.0.2\n",
    "ipython_pygments_lexers   1.1.1\n",
    "isoduration               20.11.0\n",
    "jedi                      0.19.2\n",
    "Jinja2                    3.1.6\n",
    "json5                     0.10.0\n",
    "jsonpointer               3.0.0\n",
    "jsonschema                4.23.0\n",
    "jsonschema-specifications 2024.10.1\n",
    "jupyter_client            8.6.3\n",
    "jupyter_core              5.7.2\n",
    "jupyter-events            0.12.0\n",
    "jupyter-lsp               2.2.5\n",
    "jupyter_server            2.15.0\n",
    "jupyter_server_terminals  0.5.3\n",
    "jupyterlab                4.3.6\n",
    "jupyterlab_pygments       0.3.0\n",
    "jupyterlab_server         2.27.3\n",
    "kiwisolver                1.4.8\n",
    "markdown-it-py            3.0.0\n",
    "MarkupSafe                2.1.5\n",
    "matplotlib                3.10.1\n",
    "matplotlib-inline         0.1.7\n",
    "mdurl                     0.1.2\n",
    "mistune                   3.1.3\n",
    "mpmath                    1.3.0\n",
    "narwhals                  1.31.0\n",
    "nbclient                  0.10.2\n",
    "nbconvert                 7.16.6\n",
    "nbformat                  5.10.4\n",
    "nest-asyncio              1.6.0\n",
    "networkx                  3.4.2\n",
    "notebook_shim             0.2.4\n",
    "numpy                     1.26.4\n",
    "orjson                    3.10.15\n",
    "overrides                 7.7.0\n",
    "packaging                 24.2\n",
    "pandas                    2.2.3\n",
    "pandocfilters             1.5.1\n",
    "parso                     0.8.4\n",
    "pillow                    10.4.0\n",
    "pip                       25.0\n",
    "platformdirs              4.3.6\n",
    "prometheus_client         0.21.1\n",
    "prompt_toolkit            3.0.50\n",
    "psutil                    7.0.0\n",
    "pure_eval                 0.2.3\n",
    "pycparser                 2.22\n",
    "pydantic                  2.10.6\n",
    "pydantic_core             2.27.2\n",
    "pydub                     0.25.1\n",
    "Pygments                  2.19.1\n",
    "pyparsing                 3.2.1\n",
    "python-dateutil           2.9.0.post0\n",
    "python-json-logger        3.3.0\n",
    "python-multipart          0.0.20\n",
    "pytz                      2025.1\n",
    "pywin32                   310\n",
    "pywinpty                  2.0.15\n",
    "PyYAML                    6.0.2\n",
    "pyzmq                     26.3.0\n",
    "referencing               0.36.2\n",
    "regex                     2024.11.6\n",
    "requests                  2.32.3\n",
    "rfc3339-validator         0.1.4\n",
    "rfc3986-validator         0.1.1\n",
    "rich                      13.9.4\n",
    "rpds-py                   0.23.1\n",
    "ruff                      0.11.0\n",
    "safehttpx                 0.1.6\n",
    "safetensors               0.5.3\n",
    "scipy                     1.15.2\n",
    "semantic-version          2.10.0\n",
    "Send2Trash                1.8.3\n",
    "setuptools                75.8.0\n",
    "shellingham               1.5.4\n",
    "six                       1.17.0\n",
    "sniffio                   1.3.1\n",
    "soupsieve                 2.6\n",
    "stack-data                0.6.3\n",
    "starlette                 0.46.1\n",
    "sympy                     1.13.3\n",
    "terminado                 0.18.1\n",
    "tinycss2                  1.4.0\n",
    "tokenizers                0.21.1\n",
    "tomlkit                   0.13.2\n",
    "torch                     2.4.1\n",
    "torch-directml            0.2.4.dev240913\n",
    "torchvision               0.19.1\n",
    "tornado                   6.4.2\n",
    "tqdm                      4.67.1\n",
    "traitlets                 5.14.3\n",
    "transformers              4.49.0\n",
    "typer                     0.15.2\n",
    "types-python-dateutil     2.9.0.20241206\n",
    "typing_extensions         4.12.2\n",
    "tzdata                    2025.1\n",
    "uri-template              1.3.0\n",
    "urllib3                   2.3.0\n",
    "uvicorn                   0.34.0\n",
    "wcwidth                   0.2.13\n",
    "webcolors                 24.11.1\n",
    "webencodings              0.5.1\n",
    "websocket-client          1.8.0\n",
    "websockets                11.0.3\n",
    "wheel                     0.45.1\n",
    "zipp                      3.21.0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DirectML Basic Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([25], device='privateuseone:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch_directml\n",
    "dml = torch_directml.device()\n",
    "\n",
    "tensor1 = torch.tensor([5]).to(dml)\n",
    "tensor2 = torch.tensor([5]).to(dml)\n",
    "\n",
    "dml_algebra = tensor1 * tensor2\n",
    "dml_algebra.item()\n",
    "\n",
    "print(dml_algebra)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### JSON Bert Test Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "\n",
    "# Constants\n",
    "TRAIN_GOOD_FILE_COUNT = 250\n",
    "TEST_GOOD_FILE_COUNT = 50\n",
    "TRAIN_BAD_FILE_COUNT = 250\n",
    "TEST_BAD_FILE_COUNT = 50\n",
    "DATA_FOLDER = \"data\"\n",
    "WDSDataset_FOLDER = os.path.join(DATA_FOLDER, \"benchmark_dataset\")\n",
    "\n",
    "# Generate Good files\n",
    "good_files = []\n",
    "for i in range(TRAIN_GOOD_FILE_COUNT + TEST_GOOD_FILE_COUNT):\n",
    "    data = {\n",
    "        \"id\": random.randint(100000, 999999),\n",
    "        \"name\": {\n",
    "            \"first\": f\"John\",\n",
    "            \"last\": f\"Doe {i+1}\"\n",
    "        },\n",
    "        \"age\": random.randint(18, 60),\n",
    "        \"score\": {\n",
    "            \"math\": round(random.uniform(0.6, 1.0), 2),\n",
    "            \"science\": round(random.uniform(0.6, 1.0), 2),\n",
    "            \"english\": round(random.uniform(0.6, 1.0), 2)\n",
    "        },\n",
    "        \"address\": {\n",
    "            \"street\": f\"{random.randint(100, 999)} Main St\",\n",
    "            \"city\": \"Anytown\",\n",
    "            \"state\": \"CA\",\n",
    "            \"zip\": f\"{random.randint(10000, 99999)}\"\n",
    "        },\n",
    "        \"contacts\": [\n",
    "            {\"type\": \"email\", \"value\": f\"john.doe{i+1}@example.com\"},\n",
    "            {\"type\": \"phone\", \"value\": f\"555-{random.randint(1000, 9999)}\"}\n",
    "        ]\n",
    "    }\n",
    "    good_files.append(json.dumps(data))\n",
    "\n",
    "# Generate Bad files\n",
    "bad_files = []\n",
    "for i in range(TRAIN_BAD_FILE_COUNT + TEST_BAD_FILE_COUNT):\n",
    "    data = {\n",
    "        \"id\": random.randint(100000, 999999),\n",
    "        \"name\": {\n",
    "            \"first\": f\"John\",\n",
    "            \"last\": f\"Doe {i+1}\"\n",
    "        },\n",
    "        \"age\": random.randint(18, 60),\n",
    "        \"score\": {\n",
    "            \"math\": round(random.uniform(0.4, 0.9), 2),\n",
    "            \"science\": round(random.uniform(0.4, 0.9), 2),\n",
    "            \"english\": round(random.uniform(0.4, 0.9), 2)\n",
    "        },\n",
    "        \"address\": {\n",
    "            \"street\": f\"{random.randint(100, 999)} Main St\",\n",
    "            \"city\": \"Anytown\",\n",
    "            \"state\": \"CA\",\n",
    "            \"zip\": f\"{random.randint(10000, 99999)}\"\n",
    "        },\n",
    "        \"contacts\": [\n",
    "            {\"type\": \"email\", \"value\": f\"john.doe{i+1}@example.com\"},\n",
    "            {\"type\": \"phone\", \"value\": f\"555-{random.randint(1000, 9999)}\"}\n",
    "        ],\n",
    "        \"feedback\": [\"bad\", \"not good\", \"block\"][random.randint(0, 2)]\n",
    "    }\n",
    "    bad_files.append(json.dumps(data))\n",
    "\n",
    "# Create train and test folder structure\n",
    "train_good_folder_path = os.path.join(WDSDataset_FOLDER, \"train\", \"good\")\n",
    "train_bad_folder_path = os.path.join(WDSDataset_FOLDER, \"train\", \"bad\")\n",
    "test_good_folder_path = os.path.join(WDSDataset_FOLDER, \"test\", \"good\")\n",
    "test_bad_folder_path = os.path.join(WDSDataset_FOLDER, \"test\", \"bad\")\n",
    "\n",
    "os.makedirs(train_good_folder_path, exist_ok=True)\n",
    "os.makedirs(train_bad_folder_path, exist_ok=True)\n",
    "os.makedirs(test_good_folder_path, exist_ok=True)\n",
    "os.makedirs(test_bad_folder_path, exist_ok=True)\n",
    "\n",
    "# Save Good files to train/GOOD and test/GOOD folders\n",
    "for i in range(TRAIN_GOOD_FILE_COUNT):\n",
    "    good_file_path = os.path.join(train_good_folder_path, f\"good{i+1}.json\")\n",
    "    with open(good_file_path, \"w\") as f:\n",
    "        f.write(good_files[i])\n",
    "\n",
    "for i in range(TEST_GOOD_FILE_COUNT):\n",
    "    good_file_path = os.path.join(train_good_folder_path, f\"good{i+1}.json\")\n",
    "    with open(good_file_path, \"w\") as f:\n",
    "        f.write(good_files[TRAIN_GOOD_FILE_COUNT + i])\n",
    "\n",
    "# Save Bad files to train/BAD and test/BAD folders\n",
    "for i in range(TRAIN_BAD_FILE_COUNT):\n",
    "    bad_file_path = os.path.join(train_bad_folder_path, f\"bad{i+1}.json\")\n",
    "    with open(bad_file_path, \"w\") as f:\n",
    "        f.write(bad_files[i])\n",
    "\n",
    "for i in range(TEST_BAD_FILE_COUNT):\n",
    "    bad_file_path = os.path.join(train_bad_folder_path, f\"bad{i+1}.json\")\n",
    "    with open(bad_file_path, \"w\") as f:\n",
    "        f.write(bad_files[TRAIN_BAD_FILE_COUNT + i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: privateuseone:0\n",
      "Model device: privateuseone:0\n",
      "Generated 1000 synthetic samples.\n",
      "Generated 200 synthetic samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training epoch...\n",
      "Step 0: Loss = 0.7188, Data Time = 0.000s, Compute Time = 0.132s\n",
      "Step 1: Loss = 1.0246, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 2: Loss = 0.8027, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 3: Loss = 0.6980, Data Time = 0.000s, Compute Time = 0.007s\n",
      "Step 4: Loss = 0.6531, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 5: Loss = 0.7400, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 6: Loss = 0.7147, Data Time = 0.000s, Compute Time = 0.007s\n",
      "Step 7: Loss = 0.7068, Data Time = 0.001s, Compute Time = 0.007s\n",
      "Step 8: Loss = 0.6871, Data Time = 0.000s, Compute Time = 0.007s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\phill\\miniconda3\\envs\\directml\\Lib\\site-packages\\torch\\optim\\adamw.py:529: UserWarning: The operator 'aten::lerp.Scalar_out' is not currently supported on the DML backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at C:\\__w\\1\\s\\pytorch-directml-plugin\\torch_directml\\csrc\\dml\\dml_cpu_fallback.cpp:17.)\n",
      "  torch._foreach_lerp_(device_exp_avgs, device_grads, 1 - beta1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 9: Loss = 0.6550, Data Time = 0.000s, Compute Time = 0.007s\n",
      "Step 10: Loss = 0.7140, Data Time = 0.001s, Compute Time = 0.006s\n",
      "Step 11: Loss = 0.6587, Data Time = 0.000s, Compute Time = 0.004s\n",
      "Step 12: Loss = 0.6876, Data Time = 0.000s, Compute Time = 0.009s\n",
      "Step 13: Loss = 0.7109, Data Time = 0.000s, Compute Time = 0.008s\n",
      "Step 14: Loss = 0.6758, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 15: Loss = 0.6625, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 16: Loss = 0.7093, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 17: Loss = 0.6859, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 18: Loss = 0.7316, Data Time = 0.000s, Compute Time = 0.007s\n",
      "Step 19: Loss = 0.6834, Data Time = 0.000s, Compute Time = 0.008s\n",
      "Step 20: Loss = 0.6779, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 21: Loss = 0.6772, Data Time = 0.000s, Compute Time = 0.010s\n",
      "Step 22: Loss = 0.6957, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 23: Loss = 0.6937, Data Time = 0.000s, Compute Time = 0.007s\n",
      "Step 24: Loss = 0.6877, Data Time = 0.000s, Compute Time = 0.007s\n",
      "Step 25: Loss = 0.6776, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 26: Loss = 0.6950, Data Time = 0.000s, Compute Time = 0.008s\n",
      "Step 27: Loss = 0.6885, Data Time = 0.000s, Compute Time = 0.007s\n",
      "Step 28: Loss = 0.6786, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 29: Loss = 0.6855, Data Time = 0.000s, Compute Time = 0.007s\n",
      "Step 30: Loss = 0.6978, Data Time = 0.000s, Compute Time = 0.007s\n",
      "Step 31: Loss = 0.6867, Data Time = 0.001s, Compute Time = 0.006s\n",
      "Step 32: Loss = 0.6857, Data Time = 0.000s, Compute Time = 0.007s\n",
      "Step 33: Loss = 0.6521, Data Time = 0.000s, Compute Time = 0.007s\n",
      "Step 34: Loss = 0.6730, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 35: Loss = 0.7133, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 36: Loss = 0.7313, Data Time = 0.000s, Compute Time = 0.007s\n",
      "Step 37: Loss = 0.6572, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 38: Loss = 0.6686, Data Time = 0.000s, Compute Time = 0.007s\n",
      "Step 39: Loss = 0.7004, Data Time = 0.000s, Compute Time = 0.007s\n",
      "Step 40: Loss = 0.6846, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 41: Loss = 0.7026, Data Time = 0.000s, Compute Time = 0.010s\n",
      "Step 42: Loss = 0.6845, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 43: Loss = 0.6532, Data Time = 0.000s, Compute Time = 0.007s\n",
      "Step 44: Loss = 0.6533, Data Time = 0.000s, Compute Time = 0.008s\n",
      "Step 45: Loss = 0.6175, Data Time = 0.000s, Compute Time = 0.007s\n",
      "Step 46: Loss = 0.7051, Data Time = 0.000s, Compute Time = 0.007s\n",
      "Step 47: Loss = 0.7101, Data Time = 0.000s, Compute Time = 0.007s\n",
      "Step 48: Loss = 0.7371, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 49: Loss = 0.6426, Data Time = 0.000s, Compute Time = 0.007s\n",
      "Step 50: Loss = 0.6846, Data Time = 0.000s, Compute Time = 0.007s\n",
      "Step 51: Loss = 0.7807, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 52: Loss = 0.7293, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 53: Loss = 0.6468, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 54: Loss = 0.6702, Data Time = 0.000s, Compute Time = 0.004s\n",
      "Step 55: Loss = 0.6535, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 56: Loss = 0.7159, Data Time = 0.000s, Compute Time = 0.007s\n",
      "Step 57: Loss = 0.7464, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 58: Loss = 0.7117, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 59: Loss = 0.6995, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 60: Loss = 0.6939, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 61: Loss = 0.7047, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 62: Loss = 0.6958, Data Time = 0.000s, Compute Time = 0.036s\n",
      "Training epoch complete. Total time = 0.599s\n",
      "Starting testing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:00<00:02,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing complete.\n",
      "Epoch 1 - Train Loss: 0.6979, Test Loss: 0.6908, Accuracy: 0.5350\n",
      "Starting training epoch...\n",
      "Step 0: Loss = 0.6870, Data Time = 0.000s, Compute Time = 0.050s\n",
      "Step 1: Loss = 0.6702, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 2: Loss = 0.6874, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 3: Loss = 0.6821, Data Time = 0.000s, Compute Time = 0.007s\n",
      "Step 4: Loss = 0.6773, Data Time = 0.000s, Compute Time = 0.007s\n",
      "Step 5: Loss = 0.7124, Data Time = 0.000s, Compute Time = 0.008s\n",
      "Step 6: Loss = 0.6992, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 7: Loss = 0.6842, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 8: Loss = 0.7002, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 9: Loss = 0.7045, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 10: Loss = 0.6963, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 11: Loss = 0.6977, Data Time = 0.001s, Compute Time = 0.004s\n",
      "Step 12: Loss = 0.6934, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 13: Loss = 0.6888, Data Time = 0.001s, Compute Time = 0.010s\n",
      "Step 14: Loss = 0.6809, Data Time = 0.001s, Compute Time = 0.006s\n",
      "Step 15: Loss = 0.6862, Data Time = 0.000s, Compute Time = 0.007s\n",
      "Step 16: Loss = 0.6841, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 17: Loss = 0.7079, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 18: Loss = 0.6863, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 19: Loss = 0.6835, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 20: Loss = 0.6952, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 21: Loss = 0.6997, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 22: Loss = 0.6791, Data Time = 0.000s, Compute Time = 0.003s\n",
      "Step 23: Loss = 0.6967, Data Time = 0.000s, Compute Time = 0.008s\n",
      "Step 24: Loss = 0.6878, Data Time = 0.000s, Compute Time = 0.007s\n",
      "Step 25: Loss = 0.6966, Data Time = 0.000s, Compute Time = 0.007s\n",
      "Step 26: Loss = 0.6894, Data Time = 0.002s, Compute Time = 0.006s\n",
      "Step 27: Loss = 0.6912, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 28: Loss = 0.6877, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 29: Loss = 0.6791, Data Time = 0.001s, Compute Time = 0.005s\n",
      "Step 30: Loss = 0.6933, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 31: Loss = 0.6742, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 32: Loss = 0.6871, Data Time = 0.001s, Compute Time = 0.005s\n",
      "Step 33: Loss = 0.6735, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 34: Loss = 0.6347, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 35: Loss = 0.6670, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 36: Loss = 0.6836, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 37: Loss = 0.7476, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 38: Loss = 0.6629, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 39: Loss = 0.6596, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 40: Loss = 0.7509, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 41: Loss = 0.7454, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 42: Loss = 0.7312, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 43: Loss = 0.6813, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 44: Loss = 0.6594, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 45: Loss = 0.6815, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 46: Loss = 0.6922, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 47: Loss = 0.7015, Data Time = 0.000s, Compute Time = 0.007s\n",
      "Step 48: Loss = 0.6924, Data Time = 0.001s, Compute Time = 0.006s\n",
      "Step 49: Loss = 0.6869, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 50: Loss = 0.6802, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 51: Loss = 0.6841, Data Time = 0.001s, Compute Time = 0.005s\n",
      "Step 52: Loss = 0.6842, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 53: Loss = 0.6903, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 54: Loss = 0.6834, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 55: Loss = 0.6962, Data Time = 0.001s, Compute Time = 0.006s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:01<00:01,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 56: Loss = 0.6874, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 57: Loss = 0.6862, Data Time = 0.001s, Compute Time = 0.005s\n",
      "Step 58: Loss = 0.6840, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 59: Loss = 0.6915, Data Time = 0.000s, Compute Time = 0.002s\n",
      "Step 60: Loss = 0.6983, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 61: Loss = 0.6954, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 62: Loss = 0.7431, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Training epoch complete. Total time = 0.449s\n",
      "Starting testing...\n",
      "Testing complete.\n",
      "Epoch 2 - Train Loss: 0.6908, Test Loss: 0.6915, Accuracy: 0.5350\n",
      "Starting training epoch...\n",
      "Step 0: Loss = 0.6775, Data Time = 0.001s, Compute Time = 0.005s\n",
      "Step 1: Loss = 0.6915, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 2: Loss = 0.6934, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 3: Loss = 0.6895, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 4: Loss = 0.6829, Data Time = 0.001s, Compute Time = 0.006s\n",
      "Step 5: Loss = 0.6884, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 6: Loss = 0.6814, Data Time = 0.000s, Compute Time = 0.004s\n",
      "Step 7: Loss = 0.7054, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 8: Loss = 0.6938, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 9: Loss = 0.6848, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 10: Loss = 0.6911, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 11: Loss = 0.6850, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 12: Loss = 0.6810, Data Time = 0.001s, Compute Time = 0.005s\n",
      "Step 13: Loss = 0.6851, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 14: Loss = 0.6861, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 15: Loss = 0.7012, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 16: Loss = 0.6835, Data Time = 0.001s, Compute Time = 0.004s\n",
      "Step 17: Loss = 0.6779, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 18: Loss = 0.7122, Data Time = 0.000s, Compute Time = 0.004s\n",
      "Step 19: Loss = 0.6870, Data Time = 0.001s, Compute Time = 0.005s\n",
      "Step 20: Loss = 0.6824, Data Time = 0.001s, Compute Time = 0.005s\n",
      "Step 21: Loss = 0.6915, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 22: Loss = 0.6886, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 23: Loss = 0.6827, Data Time = 0.001s, Compute Time = 0.005s\n",
      "Step 24: Loss = 0.6858, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 25: Loss = 0.6805, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 26: Loss = 0.6813, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 27: Loss = 0.6750, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 28: Loss = 0.6918, Data Time = 0.000s, Compute Time = 0.004s\n",
      "Step 29: Loss = 0.6736, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 30: Loss = 0.6831, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 31: Loss = 0.6772, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 32: Loss = 0.6570, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 33: Loss = 0.6568, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 34: Loss = 0.7919, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 35: Loss = 0.6511, Data Time = 0.000s, Compute Time = 0.003s\n",
      "Step 36: Loss = 0.6951, Data Time = 0.000s, Compute Time = 0.007s\n",
      "Step 37: Loss = 0.6827, Data Time = 0.001s, Compute Time = 0.003s\n",
      "Step 38: Loss = 0.6802, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 39: Loss = 0.6683, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 40: Loss = 0.6593, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 41: Loss = 0.6670, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 42: Loss = 0.6500, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 43: Loss = 0.7192, Data Time = 0.001s, Compute Time = 0.005s\n",
      "Step 44: Loss = 0.6976, Data Time = 0.000s, Compute Time = 0.004s\n",
      "Step 45: Loss = 0.6643, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 46: Loss = 0.6844, Data Time = 0.000s, Compute Time = 0.003s\n",
      "Step 47: Loss = 0.6918, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 48: Loss = 0.6732, Data Time = 0.000s, Compute Time = 0.007s\n",
      "Step 49: Loss = 0.6691, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 50: Loss = 0.7115, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 51: Loss = 0.6568, Data Time = 0.000s, Compute Time = 0.004s\n",
      "Step 52: Loss = 0.6601, Data Time = 0.001s, Compute Time = 0.004s\n",
      "Step 53: Loss = 0.6841, Data Time = 0.000s, Compute Time = 0.000s\n",
      "Step 54: Loss = 0.6801, Data Time = 0.000s, Compute Time = 0.003s\n",
      "Step 55: Loss = 0.6881, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 56: Loss = 0.6898, Data Time = 0.001s, Compute Time = 0.005s\n",
      "Step 57: Loss = 0.6628, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 58: Loss = 0.6852, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 59: Loss = 0.6449, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 60: Loss = 0.6636, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 61: Loss = 0.6808, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 62: Loss = 0.7312, Data Time = 0.001s, Compute Time = 0.005s\n",
      "Training epoch complete. Total time = 0.353s\n",
      "Starting testing...\n",
      "Testing complete.\n",
      "Epoch 3 - Train Loss: 0.6837, Test Loss: 0.6960, Accuracy: 0.5350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:01<00:00,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training epoch...\n",
      "Step 0: Loss = 0.5688, Data Time = 0.000s, Compute Time = 0.004s\n",
      "Step 1: Loss = 0.6826, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 2: Loss = 0.7325, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 3: Loss = 0.6983, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 4: Loss = 0.6798, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 5: Loss = 0.6459, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 6: Loss = 0.6929, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 7: Loss = 0.6550, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 8: Loss = 0.6700, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 9: Loss = 0.6621, Data Time = 0.000s, Compute Time = 0.003s\n",
      "Step 10: Loss = 0.6747, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 11: Loss = 0.6771, Data Time = 0.000s, Compute Time = 0.007s\n",
      "Step 12: Loss = 0.6711, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 13: Loss = 0.6886, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 14: Loss = 0.6751, Data Time = 0.001s, Compute Time = 0.005s\n",
      "Step 15: Loss = 0.6520, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 16: Loss = 0.6667, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 17: Loss = 0.6480, Data Time = 0.001s, Compute Time = 0.005s\n",
      "Step 18: Loss = 0.6908, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 19: Loss = 0.6358, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 20: Loss = 0.6617, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 21: Loss = 0.7077, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 22: Loss = 0.6648, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 23: Loss = 0.6090, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 24: Loss = 0.7692, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 25: Loss = 0.6702, Data Time = 0.000s, Compute Time = 0.001s\n",
      "Step 26: Loss = 0.6530, Data Time = 0.004s, Compute Time = 0.004s\n",
      "Step 27: Loss = 0.6581, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 28: Loss = 0.6794, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 29: Loss = 0.6526, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 30: Loss = 0.6557, Data Time = 0.000s, Compute Time = 0.001s\n",
      "Step 31: Loss = 0.6427, Data Time = 0.000s, Compute Time = 0.002s\n",
      "Step 32: Loss = 0.6396, Data Time = 0.000s, Compute Time = 0.007s\n",
      "Step 33: Loss = 0.6861, Data Time = 0.000s, Compute Time = 0.004s\n",
      "Step 34: Loss = 0.6794, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 35: Loss = 0.6608, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 36: Loss = 0.6680, Data Time = 0.001s, Compute Time = 0.001s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [00:01<00:00,  2.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 37: Loss = 0.6432, Data Time = 0.000s, Compute Time = 0.009s\n",
      "Step 38: Loss = 0.6405, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 39: Loss = 0.6698, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 40: Loss = 0.6574, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 41: Loss = 0.6125, Data Time = 0.000s, Compute Time = 0.007s\n",
      "Step 42: Loss = 0.6515, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 43: Loss = 0.6780, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 44: Loss = 0.6742, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 45: Loss = 0.6235, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 46: Loss = 0.6629, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 47: Loss = 0.6829, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 48: Loss = 0.6077, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 49: Loss = 0.7692, Data Time = 0.000s, Compute Time = 0.002s\n",
      "Step 50: Loss = 0.6294, Data Time = 0.000s, Compute Time = 0.008s\n",
      "Step 51: Loss = 0.7132, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 52: Loss = 0.6602, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 53: Loss = 0.6561, Data Time = 0.001s, Compute Time = 0.005s\n",
      "Step 54: Loss = 0.7246, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 55: Loss = 0.6652, Data Time = 0.000s, Compute Time = 0.004s\n",
      "Step 56: Loss = 0.6670, Data Time = 0.001s, Compute Time = 0.005s\n",
      "Step 57: Loss = 0.6449, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 58: Loss = 0.6564, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 59: Loss = 0.6368, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 60: Loss = 0.7263, Data Time = 0.000s, Compute Time = 0.007s\n",
      "Step 61: Loss = 0.7153, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 62: Loss = 0.6904, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Training epoch complete. Total time = 0.348s\n",
      "Starting testing...\n",
      "Testing complete.\n",
      "Epoch 4 - Train Loss: 0.6680, Test Loss: 0.6962, Accuracy: 0.4800\n",
      "Starting training epoch...\n",
      "Step 0: Loss = 0.6290, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 1: Loss = 0.6333, Data Time = 0.001s, Compute Time = 0.005s\n",
      "Step 2: Loss = 0.6399, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 3: Loss = 0.6496, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 4: Loss = 0.6460, Data Time = 0.000s, Compute Time = 0.007s\n",
      "Step 5: Loss = 0.6436, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 6: Loss = 0.6251, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 7: Loss = 0.6389, Data Time = 0.001s, Compute Time = 0.005s\n",
      "Step 8: Loss = 0.6184, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 9: Loss = 0.6626, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 10: Loss = 0.6146, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 11: Loss = 0.5870, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 12: Loss = 0.5291, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 13: Loss = 0.6833, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 14: Loss = 0.6283, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 15: Loss = 0.6059, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 16: Loss = 0.5613, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 17: Loss = 0.6132, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 18: Loss = 0.6402, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 19: Loss = 0.6267, Data Time = 0.001s, Compute Time = 0.005s\n",
      "Step 20: Loss = 0.5791, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 21: Loss = 0.6280, Data Time = 0.001s, Compute Time = 0.004s\n",
      "Step 22: Loss = 0.5405, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 23: Loss = 0.6098, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 24: Loss = 0.5177, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 25: Loss = 0.6571, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 26: Loss = 0.6228, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 27: Loss = 0.5779, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 28: Loss = 0.5997, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 29: Loss = 0.5850, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 30: Loss = 0.5868, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 31: Loss = 0.7893, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 32: Loss = 0.6103, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 33: Loss = 0.5359, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 34: Loss = 0.5826, Data Time = 0.000s, Compute Time = 0.004s\n",
      "Step 35: Loss = 0.5793, Data Time = 0.000s, Compute Time = 0.000s\n",
      "Step 36: Loss = 0.6723, Data Time = 0.000s, Compute Time = 0.000s\n",
      "Step 37: Loss = 0.7239, Data Time = 0.000s, Compute Time = 0.015s\n",
      "Step 38: Loss = 0.5651, Data Time = 0.000s, Compute Time = 0.000s\n",
      "Step 39: Loss = 0.6086, Data Time = 0.000s, Compute Time = 0.000s\n",
      "Step 40: Loss = 0.5765, Data Time = 0.000s, Compute Time = 0.016s\n",
      "Step 41: Loss = 0.5689, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 42: Loss = 0.5676, Data Time = 0.000s, Compute Time = 0.004s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:02<00:00,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 43: Loss = 0.6268, Data Time = 0.001s, Compute Time = 0.004s\n",
      "Step 44: Loss = 0.5431, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 45: Loss = 0.6512, Data Time = 0.000s, Compute Time = 0.004s\n",
      "Step 46: Loss = 0.5627, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 47: Loss = 0.5430, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 48: Loss = 0.6326, Data Time = 0.001s, Compute Time = 0.005s\n",
      "Step 49: Loss = 0.6196, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 50: Loss = 0.6232, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 51: Loss = 0.5650, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 52: Loss = 0.5529, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 53: Loss = 0.5767, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 54: Loss = 0.6671, Data Time = 0.000s, Compute Time = 0.006s\n",
      "Step 55: Loss = 0.7867, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 56: Loss = 0.5360, Data Time = 0.001s, Compute Time = 0.005s\n",
      "Step 57: Loss = 0.5918, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 58: Loss = 0.6800, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 59: Loss = 0.5392, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 60: Loss = 0.5694, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 61: Loss = 0.6086, Data Time = 0.000s, Compute Time = 0.005s\n",
      "Step 62: Loss = 0.5876, Data Time = 0.001s, Compute Time = 0.004s\n",
      "Training epoch complete. Total time = 0.355s\n",
      "Starting testing...\n",
      "Testing complete.\n",
      "Epoch 5 - Train Loss: 0.6099, Test Loss: 0.7166, Accuracy: 0.4700\n",
      "Total elapsed time: 2.18 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"DISABLE_TORCH_HALF\"] = \"1\"\n",
    "\n",
    "import torch\n",
    "import torch_directml\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import tqdm\n",
    "\n",
    "# Set device\n",
    "device = torch_directml.device(0)\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "# Synthetic Dataset\n",
    "class SyntheticDataset(Dataset):\n",
    "    def __init__(self, num_samples=1000, img_size=32, num_classes=2):\n",
    "        self.num_samples = num_samples\n",
    "        self.data = torch.randn(num_samples, 3, img_size, img_size)  # [N, C, H, W]\n",
    "        self.labels = torch.randint(0, num_classes, (num_samples,))  # Binary labels\n",
    "        print(f\"Generated {num_samples} synthetic samples.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input': self.data[idx],\n",
    "            'label': self.labels[idx]\n",
    "        }\n",
    "\n",
    "# Simple CNN Model\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)  # 3 input channels -> 16\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)  # 16 -> 32\n",
    "        self.pool = nn.MaxPool2d(2, 2)  # Downsample by 2x\n",
    "        self.fc1 = nn.Linear(32 * 8 * 8, 128)  # After 2 pooling layers: 32x8x8\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))  # [B, 16, 16, 16]\n",
    "        x = self.pool(self.relu(self.conv2(x)))  # [B, 32, 8, 8]\n",
    "        x = x.view(x.size(0), -1)  # Flatten: [B, 32*8*8]\n",
    "        x = self.relu(self.fc1(x))  # [B, 128]\n",
    "        x = self.fc2(x)  # [B, num_classes]\n",
    "        return x\n",
    "\n",
    "# Initialize model, loss, and optimizer\n",
    "model = SimpleCNN(num_classes=2).to(device).float()\n",
    "print(f\"Model device: {next(model.parameters()).device}\")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001)\n",
    "\n",
    "# Data\n",
    "train_dataset = SyntheticDataset(num_samples=1000)\n",
    "test_dataset = SyntheticDataset(num_samples=200)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=0, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "# Training function\n",
    "def train_epoch(model, train_loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    print(\"Starting training epoch...\")\n",
    "    epoch_start = time.time()\n",
    "    for step, batch in enumerate(train_loader):\n",
    "        data_start = time.time()\n",
    "        inputs = batch['input'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        data_time = time.time() - data_start\n",
    "        step_start = time.time()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        step_time = time.time() - step_start\n",
    "        print(f\"Step {step}: Loss = {loss.item():.4f}, Data Time = {data_time:.3f}s, Compute Time = {step_time:.3f}s\")\n",
    "    \n",
    "    epoch_time = time.time() - epoch_start\n",
    "    print(f\"Training epoch complete. Total time = {epoch_time:.3f}s\")\n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "# Testing function\n",
    "def test_model(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    print(\"Starting testing...\")\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            inputs = batch['input'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = correct / total\n",
    "    print(\"Testing complete.\")\n",
    "    return total_loss / len(test_loader), accuracy\n",
    "\n",
    "# Training loop\n",
    "epochs = 5\n",
    "start_time = time.time()\n",
    "for epoch in tqdm.tqdm(range(epochs)):\n",
    "    train_loss = train_epoch(model, train_loader, criterion, optimizer)\n",
    "    test_loss, accuracy = test_model(model, test_loader, criterion)\n",
    "    print(f\"Epoch {epoch+1} - Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Total elapsed time: {elapsed_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "AMD Radeon RX 9070 XT\u0000\n"
     ]
    }
   ],
   "source": [
    "import torch_directml\n",
    "print(torch_directml.device_count())  # Should print > 0\n",
    "print(torch_directml.device_name(0))  # Should show your AMD GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "directml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
